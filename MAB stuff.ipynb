{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "533964ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4389357f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54c46d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "<>:9: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "C:\\Users\\chinm\\AppData\\Local\\Temp\\ipykernel_19516\\3575554782.py:9: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(arm in list(range(self.n_arms)), \"Invalid arm {}, only {} arms\".format(arm, self.n_arms))\n"
     ]
    }
   ],
   "source": [
    "class MABEnvironment:\n",
    "    \n",
    "    # Initializes the reward distribution, number of arms and list of parameters\n",
    "    def __init__(self, reward_dist:str =\"Bernoulli\", n_arms:int =5,\n",
    "                 param_list:np.ndarray[int]=np.array([0.1, 0.2, 0.3, 0.4, 0.5])):\n",
    "        self.reward_dist = reward_dist\n",
    "        self.n_arms = 5\n",
    "        self.param_list = param_list\n",
    "    \n",
    "    # Takes one step by pulling the specified arm, returns the stochastic reward\n",
    "    def step(self, arm):\n",
    "        assert(arm in list(range(self.n_arms)), \"Invalid arm {}, only {} arms\".format(arm, self.n_arms))\n",
    "        \n",
    "        # Bernoulli rewards implemented\n",
    "        if(self.reward_dist == \"Bernoulli\"):\n",
    "            reward = np.random.binomial(1, self.param_list[arm])\n",
    "            \n",
    "        return reward\n",
    "    \n",
    "    # Returns an array of regret values \n",
    "    def run_alg_regret(alg, steps = 30):\n",
    "        \n",
    "        if(reward_dist == 'Bernoulli'):\n",
    "            best_arm = np.argmax(self.param_list)\n",
    "            best_mean_reward = self.param_list[best_arm]\n",
    "            \n",
    "        reward_array = np.array([])\n",
    "        arm = np.random.choice(np.arange(0,self.n_arms))\n",
    "        arm_array = np.array([arm])\n",
    "            \n",
    "        for i in range(steps):\n",
    "            reward = self.step(arm)\n",
    "            reward_array = np.append(reward_array, reward)\n",
    "            next_arm = alg(reward_array, arm_array, steps, n_arms)\n",
    "            arm_array = np.append(arm_array, next_arm)\n",
    "        \n",
    "        regret_array = np.array([(steps*best_mean_reward - np.sum(reward_array[:i])) for i in range(1,steps+1)])\n",
    "        \n",
    "        return regret_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bc31286",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlineMABAlgorithm:\n",
    "    \n",
    "    def __init__(steps:int, n_arms:int):\n",
    "        self.steps = steps\n",
    "        self.n_arms = n_arms\n",
    "        \n",
    "    def choose_arm(step_num):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def update(arm, reward, step_num):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6263599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETC(OnlineMABAlgorithm):\n",
    "    \n",
    "    def __init__(steps:int, n_arms:int, explore_ct:int):\n",
    "        super().__init__(steps,n_arms)\n",
    "        self.explore_ct = explore_ct\n",
    "        self.etc_reward_list = np.zeros(n_arms)\n",
    "        self.arm_count = np.zeros(n_arms)\n",
    "        \n",
    "    def choose_arm(step_num):\n",
    "        if(step_num <= self.n_arms*self.explore_ct):\n",
    "            arm = step_num%self.n_arms\n",
    "        else:\n",
    "            arm = np.argmax(self.etc_reward_list)\n",
    "        return arm\n",
    "        \n",
    "    def update(arm, reward, step_num):\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7e8be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCB(OnlineMABAlgorithm):\n",
    "    \n",
    "    def __init__(self, steps:int, n_arms:int):\n",
    "        super().__init__(steps, n_arms)\n",
    "        self.ucb_reward_list = np.ones(n_arms)*np.inf\n",
    "        self.arm_count = np.zeros(n_arms)\n",
    "    \n",
    "    def update(arm, reward, step_num):\n",
    "        self.arm_count[arm] +=1\n",
    "        if(self.ucb_reward_list[arm] == np.inf):\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d2db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac4e047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.inf +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f777d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
